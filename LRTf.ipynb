{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12923427647247822227\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(boston.data)\n",
    "labels = np.array(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((506, 13), (506,))\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 1)\n"
     ]
    }
   ],
   "source": [
    "labels = np.reshape(labels, [-1,1])\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(data):\n",
    "    # X-mean(X) / std(X)\n",
    "    m = np.mean(data)\n",
    "    s = np.std(data)\n",
    "    normalised_data = (data-m)/s\n",
    "    return normalised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = norm(features)\n",
    "labels = norm(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_features = np.ones(shape = (features.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((bias_features, features), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features,labels, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((404, 14), (404, 1))\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = features.shape[0]\n",
    "n_features = features.shape[1]\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32,shape=[None,n_features])\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(14, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.random_normal(shape=(n_features,1)))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.matmul(x,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(y_pred-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1\n",
      "Training Loss: 17.381285\tTesting Loss: 17.832302\n",
      "=====================\n",
      "Epoch2\n",
      "Training Loss: 16.562515\tTesting Loss: 16.981602\n",
      "=====================\n",
      "Epoch3\n",
      "Training Loss: 15.784311\tTesting Loss: 16.173313\n",
      "=====================\n",
      "Epoch4\n",
      "Training Loss: 15.044664\tTesting Loss: 15.40533\n",
      "=====================\n",
      "Epoch5\n",
      "Training Loss: 14.341664\tTesting Loss: 14.67565\n",
      "=====================\n",
      "Epoch6\n",
      "Training Loss: 13.673492\tTesting Loss: 13.982364\n",
      "=====================\n",
      "Epoch7\n",
      "Training Loss: 13.03843\tTesting Loss: 13.323666\n",
      "=====================\n",
      "Epoch8\n",
      "Training Loss: 12.434829\tTesting Loss: 12.697835\n",
      "=====================\n",
      "Epoch9\n",
      "Training Loss: 11.861133\tTesting Loss: 12.103239\n",
      "=====================\n",
      "Epoch10\n",
      "Training Loss: 11.315861\tTesting Loss: 11.5383215\n",
      "=====================\n",
      "Epoch11\n",
      "Training Loss: 10.797606\tTesting Loss: 11.00161\n",
      "=====================\n",
      "Epoch12\n",
      "Training Loss: 10.305026\tTesting Loss: 10.491696\n",
      "=====================\n",
      "Epoch13\n",
      "Training Loss: 9.836852\tTesting Loss: 10.007254\n",
      "=====================\n",
      "Epoch14\n",
      "Training Loss: 9.391873\tTesting Loss: 9.547011\n",
      "=====================\n",
      "Epoch15\n",
      "Training Loss: 8.968941\tTesting Loss: 9.109764\n",
      "=====================\n",
      "Epoch16\n",
      "Training Loss: 8.566961\tTesting Loss: 8.69437\n",
      "=====================\n",
      "Epoch17\n",
      "Training Loss: 8.184897\tTesting Loss: 8.299741\n",
      "=====================\n",
      "Epoch18\n",
      "Training Loss: 7.821762\tTesting Loss: 7.9248443\n",
      "=====================\n",
      "Epoch19\n",
      "Training Loss: 7.476619\tTesting Loss: 7.5686965\n",
      "=====================\n",
      "Epoch20\n",
      "Training Loss: 7.1485753\tTesting Loss: 7.230364\n",
      "=====================\n",
      "Epoch21\n",
      "Training Loss: 6.836783\tTesting Loss: 6.90896\n",
      "=====================\n",
      "Epoch22\n",
      "Training Loss: 6.540439\tTesting Loss: 6.603643\n",
      "=====================\n",
      "Epoch23\n",
      "Training Loss: 6.258775\tTesting Loss: 6.31361\n",
      "=====================\n",
      "Epoch24\n",
      "Training Loss: 5.991066\tTesting Loss: 6.0381007\n",
      "=====================\n",
      "Epoch25\n",
      "Training Loss: 5.73662\tTesting Loss: 5.776391\n",
      "=====================\n",
      "Epoch26\n",
      "Training Loss: 5.49478\tTesting Loss: 5.5277944\n",
      "=====================\n",
      "Epoch27\n",
      "Training Loss: 5.264921\tTesting Loss: 5.291656\n",
      "=====================\n",
      "Epoch28\n",
      "Training Loss: 5.046448\tTesting Loss: 5.067356\n",
      "=====================\n",
      "Epoch29\n",
      "Training Loss: 4.8387995\tTesting Loss: 4.8543043\n",
      "=====================\n",
      "Epoch30\n",
      "Training Loss: 4.6414375\tTesting Loss: 4.6519403\n",
      "=====================\n",
      "Epoch31\n",
      "Training Loss: 4.453853\tTesting Loss: 4.45973\n",
      "=====================\n",
      "Epoch32\n",
      "Training Loss: 4.275561\tTesting Loss: 4.277168\n",
      "=====================\n",
      "Epoch33\n",
      "Training Loss: 4.106101\tTesting Loss: 4.103773\n",
      "=====================\n",
      "Epoch34\n",
      "Training Loss: 3.9450366\tTesting Loss: 3.9390872\n",
      "=====================\n",
      "Epoch35\n",
      "Training Loss: 3.7919507\tTesting Loss: 3.782677\n",
      "=====================\n",
      "Epoch36\n",
      "Training Loss: 3.646448\tTesting Loss: 3.634128\n",
      "=====================\n",
      "Epoch37\n",
      "Training Loss: 3.508153\tTesting Loss: 3.4930491\n",
      "=====================\n",
      "Epoch38\n",
      "Training Loss: 3.376709\tTesting Loss: 3.3590674\n",
      "=====================\n",
      "Epoch39\n",
      "Training Loss: 3.2517765\tTesting Loss: 3.2318277\n",
      "=====================\n",
      "Epoch40\n",
      "Training Loss: 3.133031\tTesting Loss: 3.1109939\n",
      "=====================\n",
      "Epoch41\n",
      "Training Loss: 3.0201688\tTesting Loss: 2.9962451\n",
      "=====================\n",
      "Epoch42\n",
      "Training Loss: 2.9128964\tTesting Loss: 2.887279\n",
      "=====================\n",
      "Epoch43\n",
      "Training Loss: 2.810938\tTesting Loss: 2.7838051\n",
      "=====================\n",
      "Epoch44\n",
      "Training Loss: 2.7140296\tTesting Loss: 2.685549\n",
      "=====================\n",
      "Epoch45\n",
      "Training Loss: 2.621921\tTesting Loss: 2.5922508\n",
      "=====================\n",
      "Epoch46\n",
      "Training Loss: 2.5343747\tTesting Loss: 2.503662\n",
      "=====================\n",
      "Epoch47\n",
      "Training Loss: 2.4511647\tTesting Loss: 2.419547\n",
      "=====================\n",
      "Epoch48\n",
      "Training Loss: 2.3720756\tTesting Loss: 2.3396816\n",
      "=====================\n",
      "Epoch49\n",
      "Training Loss: 2.2969036\tTesting Loss: 2.263854\n",
      "=====================\n",
      "Epoch50\n",
      "Training Loss: 2.2254548\tTesting Loss: 2.1918614\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(num_epochs):\n",
    "        sess.run(opt,feed_dict={\n",
    "            x: X_train,\n",
    "            y: Y_train\n",
    "        })\n",
    "        train_loss = sess.run(cost,feed_dict={\n",
    "            x: X_train,\n",
    "            y: Y_train\n",
    "        })\n",
    "        test_loss = sess.run(cost,feed_dict={\n",
    "            x: X_test,\n",
    "            y: Y_test\n",
    "        })\n",
    "        \n",
    "        print('Epoch'+str(epoch+1))\n",
    "        print('Training Loss: '+str(train_loss)+'\\tTesting Loss: '+str(test_loss))\n",
    "        print('=====================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
